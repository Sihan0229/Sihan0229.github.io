---
layout: post  
title: "XJTU-AUTO300527 notes"  
date: 2024-05-29 00:10 +0800  
last_modified_at: 2024-05-29 00:10 +0800  
tags: [Course Note]  
math: true  r
toc: true  
excerpt: "一些疑难点的解决（只是不懂的东西大杂烩）"
---

## 求解线性回归模型（p173-178）
训练数据为𝑁个输入数据
$$\mathbf{X} =\begin{pmatrix}\mathbf{x_1},\mathbf{x_2},\cdots\mathbf{x_N}
\end{pmatrix}$$
及对应函数值
$$\mathbf{t} =\begin{pmatrix}{t_1},{t_2},\cdots{t_N}
\end{pmatrix}$$
模型为线性回归模型 
$$y(\mathbf{x},\mathbf{w}) =\mathbf{w}^T\mathbf{\phi(x)}$$

$$
  \mathbf{t} =\begin{pmatrix}
  t_{0}\\
  t_{1} \\
  \vdots \\  
  t_{N}  \\
  \end{pmatrix}_{N \times 1}
$$

$$
  \mathbf{w} =\begin{pmatrix}
  w_{0}\\
  w_{1} \\
  \vdots \\  
  w_{M-1}  \\
  \end{pmatrix}_{(M-1) \times 1}
$$


$$
  \mathbf{\phi}=
  \begin{pmatrix}
  \phi^T(x_1)\\
  \phi^T(x_2)\\
  \vdots \\  
  \phi^T(x_N)\\
  
  \end{pmatrix}=
  \begin{pmatrix}
  \phi_{0}(x_1) & \phi_{1}(x_1) & \phi_{2}(x_1) & \cdots & \phi_{M-1}(x_1)\\
  \phi_{0}(x_2) & \phi_{1}(x_2) & \phi_{2}(x_2) & \cdots & \phi_{M-1}(x_2)\\
  \vdots & \vdots & \ddots & \vdots \\  
  \phi_{0}(x_N) & \phi_{1}(x_N) & \phi_{2}(x_N) & \cdots & \phi_{M-1}(x_N)\\
  \end{pmatrix}_{N\times M}
$$

因此平方和误差函数

$$
 E_D(\mathbf{w})=\frac{1}{2}  \sum_{n=1}^N (t_n-\mathbf{w}^T \mathbf{\phi}(\mathbf{x}_n))^2 $$

 求导得

 $$\nabla E_D(\mathbf{w})=\sum_{n=1}^N (t_n-\mathbf{w}^T \mathbf{\phi}(\mathbf{x}_n))\mathbf{\phi}(\mathbf{x}_n)^T 
$$

合并可得

$$
\nabla E_D(\mathbf{w}) = \left(
\begin{pmatrix}
t_{0} &t_{1}&\cdots &t_{N}
\end{pmatrix} - \begin{pmatrix}
w_{0} &  w_{1}& \cdots & w_{M-1}
\end{pmatrix} \begin{pmatrix}
\phi(x_1) &  \phi(x_2)& \cdots & \phi(x_N)
\end{pmatrix}\right)

\begin{pmatrix}
\phi^T(x_1)\\
\phi^T(x_2)\\
\vdots \\  
\phi^T(x_N)\\

\end{pmatrix}
$$

即

$$\nabla E_D(\mathbf{w})= \left(\begin{pmatrix}
t_{0}\\
t_{1} \\
\vdots \\  
t_{N}  \\
\end{pmatrix}^T - \begin{pmatrix}
w_{0}\\
w_{1} \\
\vdots \\  
w_{M-1}  \\
\end{pmatrix}^T \begin{pmatrix}
\phi_{0}(x_1) & \phi_{1}(x_1) & \phi_{2}(x_1) & \cdots & \phi_{M-1}(x_1)\\
\phi_{0}(x_2) & \phi_{1}(x_2) & \phi_{2}(x_2) & \cdots & \phi_{M-1}(x_2)\\
\vdots & \vdots & \ddots & \vdots \\  
\phi_{0}(x_N) & \phi_{1}(x_N) & \phi_{2}(x_N) & \cdots & \phi_{M-1}(x_N)\\
\end{pmatrix}^T\right)\begin{pmatrix}
\phi_{0}(x_1) & \phi_{1}(x_1) & \phi_{2}(x_1) & \cdots & \phi_{M-1}(x_1)\\
\phi_{0}(x_2) & \phi_{1}(x_2) & \phi_{2}(x_2) & \cdots & \phi_{M-1}(x_2)\\
\vdots & \vdots & \ddots & \vdots \\  
\phi_{0}(x_N) & \phi_{1}(x_N) & \phi_{2}(x_N) & \cdots & \phi_{M-1}(x_N)\\
\end{pmatrix}
$$

即

$$
\nabla E_D(\mathbf{w})=(\mathbf{t}^T-\mathbf{w}^T\mathbf{\Phi}^T)\mathbf{\Phi}
$$

令其为0可得

$$
\mathbf{t}^T\mathbf{\Phi}=\mathbf{w}^T\mathbf{\Phi}^T\mathbf{\Phi}
$$

$$
(\mathbf{t}^T\mathbf{\Phi})^T=(\mathbf{w}^T\mathbf{\Phi}^T\mathbf{\Phi})^T
$$

$$
\mathbf{\Phi}^T\mathbf{t}=\mathbf{\Phi}^T\mathbf{\Phi}\mathbf{w}
$$

$$
\mathbf{w}_{ML}=(\mathbf{\Phi}^T\mathbf{\Phi})^{-1}\mathbf{\Phi}^T\mathbf{t}
$$

## 逻辑回归

## 吉布斯分布

## 隐马尔可夫模型（三个基本问题）

## 重要采样

基于假设：无法直接从p(z)中采样，但对于任一给定的z值，可以很容易地计算p(z)的值。仿照拒绝采样的思路，可以利用提议分布;与拒绝采样不同的是：提议分布要使用**最优**的采样函数，**不用一定全部覆盖**原分布函数；并且所有生成的样本都会被保留。

如果直接从p(z)中采样，如果有服从p(z)的L个独立样本，就可以从

$$
E(f)=\int f(\mathbf{z})p(\mathbf{z})d\mathbf{z}
$$

过渡到

$$
f\approx\frac{1}{L}  \sum_{l=1}^L f(\mathbf{z}^{(l)})
$$

因此我们可以从q(z)中采样，乘一个系数，将q(z)当作p(z)的作用，从

$$
E(f)=\int f(\mathbf{z})\frac{p(\mathbf{z})}{q(\mathbf{z})} q(\mathbf{z})d\mathbf{z}
$$

过渡到

$$
\hat f\approx\frac{1}{L}  \sum_{l=1}^L \frac{p(\mathbf{z}^{(l)})}{q(\mathbf{z}^{(l)})}f(\mathbf{z}^{(l)})
$$

乘上的这个系数是**重要性权重**

$$
r_l=\frac{p(\mathbf{z}^{(l)})}{q(\mathbf{z}^{(l)})}
$$

此外采样得到的需要归一化，因此引入

$$
p(\mathbf{z})= \frac{1}{Z_p} \tilde p(\mathbf{z})
$$

$$
q(\mathbf{z})= \frac{1}{Z_q} \tilde q(\mathbf{z})
$$

这样期望就变成了

$$
E(f)=\int f(\mathbf{z})p(\mathbf{z})d\mathbf{z}
=\int f(\mathbf{z})\frac{p(\mathbf{z})}{q(\mathbf{z})} q(\mathbf{z})d\mathbf{z}
=\frac{Z_q}{Z_p} \int f(\mathbf{z})\frac{\tilde p(\mathbf{z})}{ \tilde q(\mathbf{z})}  q(\mathbf{z})d\mathbf{z}
$$

$$
\approx\frac{Z_q}{Z_p} \frac{1}{L}  \sum_{l=1}^L \frac{\tilde p(\mathbf{z}^{(l)})}{\tilde q(\mathbf{z}^{(l)})}f(\mathbf{z}^{(l)})
=\frac{Z_q}{Z_p} \frac{1}{L}  \sum_{l=1}^L \tilde r_l f(\mathbf{z}^{(l)})
=\frac{Z_q}{\int \tilde p(\mathbf{z})d\mathbf{z}} \frac{1}{L}  \sum_{l=1}^L \tilde r_l f(\mathbf{z}^{(l)})
$$

$$
=\frac{Z_q}{\int \frac {\tilde p(\mathbf{z})}{\frac{\tilde q(\mathbf{z})}{Z_q}} q(\mathbf{z}) d\mathbf{z}} \frac{1}{L}  \sum_{l=1}^L \tilde r_l f(\mathbf{z}^{(l)})
=\frac{\frac{1}{L}  \sum_{l=1}^L \tilde r_l f(\mathbf{z}^{(l)})}{\int \frac {\tilde p(\mathbf{z})}{\tilde q(\mathbf{z})} q(\mathbf{z}) d\mathbf{z}} 
=\frac{\frac{1}{L}  \sum_{l=1}^L \tilde r_l f(\mathbf{z}^{(l)})}{\frac{1}{L}  \sum_{l=1}^L \tilde r_l } 
$$

$$
=\frac{  \sum_{l=1}^L \tilde r_l f(\mathbf{z}^{(l)})}{  \sum_{l=1}^L \tilde r_l } 
=\sum_{l=1}^L\frac{   \tilde r_l }{  \sum_{m=1}^M \tilde r_m } f(\mathbf{z}^{(l)})
=\sum_{l=1}^L\frac{   \frac{\tilde p(\mathbf{z}^{(l)})}{\tilde q(\mathbf{z}^{(l)})} }{  \sum_{m=1}^M \frac{\tilde p(\mathbf{z}^{(m)})}{\tilde q(\mathbf{z}^{(m)})} } f(\mathbf{z}^{(l)})
=\sum_{l=1}^Lw_l f(\mathbf{z}^{(l)})
$$

## Metropolis-Hasting方法（p525-526）

