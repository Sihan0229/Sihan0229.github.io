---
layout: post  
title: "XJTU-ELEC427304 Big Data Notes"  
date: 2024-06-04 19:10 +0800  
last_modified_at: 2024-06-09 19:18 +0800  
tags: [Course Note]  
math: true  r
toc: true 
excerpt: "Course notes of XJTU-ELEC427304 (TBC)."
---
<style>
        h1 { font: 26pt Times !important; }
        h2 { font: 20pt Times !important; }
        h3 { font: 16pt Times !important; }
</style>

# Introduction

**PAC - probably Approximately Correct learning model**

$$
P(|f(x)-y|\le \epsilon)\ge 1-\delta
$$

**Data Types**

+ Continuous, Binary
+ Discrete, String
+ Symbolic

**Big Data** is high-volume, high-velocity, high-variety, demanding cost-effective, innovative forms of imformation processing, whose size is beyongd the ability of typical database software tools to capture, store, manage, and analyze.

**Data Mining** is the process of discovering patterns in large data set, including intersection of ML, statistic and database systems.

ä¹ é¢˜1ï¼šå¤§æ•°æ®çš„ç‰¹ç‚¹åŒ…æ‹¬ç±»å‹å¤šã€å¯¹å¤„ç†å®æ—¶æ€§è¦æ±‚é«˜ã€å®¹é‡å¤§

ä¹ é¢˜2ï¼šç†æƒ³çš„æ•°æ®æŒ–æ˜ç®—æ³•å¾—åˆ°çš„ç»“æœåº”è¯¥æ˜¯ï¼šUseful, Hidden, Interesting

**Source & Materials**
[KDnuggets](https://www.kdnuggets.com/), [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets.php)

**Framework of ML**

+ Step 1: function with unknown

$$
y=f_\theta(x)
$$

+ Step 2: define loss from training data

$$
L(\theta)
$$

+ Step 3: optimization

$$
\theta^* = \arg \min_{\theta} \mathcal{L}
$$

**DM Techniques - Classification**
Decision Trees, K-Nearest Neighbours, Neural Networks, Support Vector Machines

# Evaluation method of model

## Data Segmentation

**hold-out ç•™å‡ºæ³•** ä¿æŒæ•°æ®åˆ†å¸ƒä¸€è‡´æ€§ï¼Œå¤šæ¬¡é‡å¤éšæœºåˆ’åˆ†ï¼Œæµ‹è¯•é›†ä¸èƒ½å¤ªå¤§ã€ä¸èƒ½å¤ªå°

**cross-validation äº¤å‰éªŒè¯æ³•** kæŠ˜äº¤å‰éªŒè¯

**boostrapping è‡ªåŠ©æ³•** æœ‰æ”¾å›/å¯é‡å¤é‡‡æ ·ï¼Œæ•°æ®åˆ†å¸ƒæœ‰æ‰€æ”¹å˜ï¼Œè®­ç»ƒé›†ä¸åŸæ ·æœ¬é›†åŒè§„æ¨¡
ï¼ˆåŒ…å¤–ä¼°è®¡ out-of-bag estimationï¼‰

## Model performance

**Error rate é”™è¯¯ç‡**

$$
E(ğ‘“;ğ·)=\frac{1}{m}\Sigma_{i=1}^{m}I(f(ğ’™_i)â‰ ğ‘¦)
$$

**Accuracy ç²¾åº¦**

$$
Acc(ğ‘“;ğ·)=\frac{1}{m}\Sigma_{i=1}^{m}I(f(ğ’™_i)=ğ‘¦)=1-E(ğ‘“;ğ·)
$$

**Precision æŸ¥å‡†ç‡**

$$
P=\frac{TP}{TP+FP}
$$

**Recall æŸ¥å…¨ç‡**

$$
R=\frac{TP}{TP+FN}
$$

**F1**

$$
\frac{1}{F_1}=\frac{1}{2}(\frac{1}{R}+\frac{1}{P})
$$

**FÎ²**

$$
\frac{1}{F_\beta}=\frac{1}{1+\beta^2}(\frac{\beta^2}{R}+\frac{1}{P})
$$

**Confusion Matrix æ··æ·†çŸ©é˜µ**

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/ConfusionMatrix.png?raw=true" width="100%">

**P-Ræ›²çº¿**

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/pr.png?raw=true" width="60%">

**BEP å¹³è¡¡ç‚¹ Break-Even Point** æŸ¥å‡†ç‡ = æŸ¥å…¨ç‡çš„å–å€¼

**ROC å—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿**

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/roc.png?raw=true" width="100%">

**AUC**ï¼šROCæ›²çº¿ä¸‹é¢ç§¯

How to Construct an ROC curve

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/rocCurve.png?raw=true" width="100%">

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/rocCurve2.png?raw=true" width="100%">

**Cost Matrix**
Cost-sensitive error rate and cost curve

C(i,j)ï¼šCost of misclassifying class j example as class i

**Cost VS Accuracy**

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/cost_vs_accuracy.png?raw=true" width="100%">

**Lift Analysis**

[[æ¨¡å‹è§£é‡‹ç­–ç•¥]Lift Chart, Permutation Importance, LIME](https://yulongtsai.medium.com/lift-chart-permutation-importance-lime-c22be8bdaf48)

ä¾‹é¢˜ï¼šå‡è®¾ç›®æ ‡å®¢æˆ·å äººç¾¤çš„5%ï¼Œç°æ ¹æ®ç”¨æˆ·æ¨¡å‹è¿›è¡Œæ‰“åˆ†æ’åºï¼Œ
å–1000åæ½œåœ¨å®¢æˆ·ä¸­æ’åå‰10%çš„å®¢æˆ·ï¼Œå‘ç°å…¶ä¸­åŒ…å«25åç›®
æ ‡å®¢æˆ·ï¼Œé—®æ­¤æ¨¡å‹åœ¨10%å¤„çš„æå‡åº¦æ˜¯å¤šå°‘?

ç­”æ¡ˆï¼š5

ä¾‹é¢˜ï¼šæˆ‘ä»¬é€šå¸¸å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†ï¼ŒéªŒè¯é›†å’Œæµ‹è¯•é›†è¿›è¡Œæ¨¡å‹çš„è®­
ç»ƒï¼Œå‚æ•°çš„éªŒè¯éœ€è¦åœ¨**éªŒè¯é›†**ä¸Šè¿›è¡Œï¼Œå‚æ•°ç¡®å®šå**éœ€è¦**é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚

ä¾‹é¢˜ï¼šå½“è¥¿ç“œæ”¶è´­å…¬å¸å»ç“œæ‘Šæ”¶è´­è¥¿ç“œæ—¶æ—¢å¸Œæœ›æŠŠå¥½ç“œéƒ½æ”¶èµ°åˆä¿è¯æ”¶
åˆ°çš„ç“œä¸­åç“œå°½å¯èƒ½çš„å°‘ï¼Œè¯·é—®ä»–åº”è¯¥è€ƒè™‘ä»€ä¹ˆè¯„ä»·æŒ‡æ ‡ï¼Ÿ

æ­£ç¡®ï¼š**F1è°ƒå’Œå¹³å‡**ä¸**BEP**

ä¾‹é¢˜ï¼šå‡è®¾æˆ‘ä»¬å·²ç»å»ºç«‹å¥½äº†ä¸€ä¸ªäºŒåˆ†ç±»æ¨¡å‹,è¾“å‡ºæ˜¯0æˆ–1,åˆå§‹é˜ˆå€¼è®¾
ç½®ä¸º05 è¶…è¿‡0.5æ¦‚ç‡ä¼°è®¡å°±åˆ¤åˆ«ä¸º1,å¦åˆ™å°±åˆ¤åˆ«ä¸º0;å¦‚æœæˆ‘ä»¬ç°
åœ¨ç”¨å¦ä¸€ä¸ªå¤§äº0.5çš„é˜ˆå€¼ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œä¸‹åˆ—è¯´æ³•æ­£ç¡®çš„æ˜¯ï¼š**æŸ¥å‡†ç‡ä¼šä¸Šå‡æˆ–ä¸å˜ï¼ŒæŸ¥å…¨ç‡ä¼šä¸‹é™æˆ–ä¸å˜**

**DM Techniques - Classification**:Â K-Means, Sequential Leader, Affinity Propagation

**DM Techniques â€“ Association Rule**

**DM Techniques â€“ Regression**

# Data Preprocessing
**Typical lssues** : ç¼ºå°‘å±æ€§å€¼Missing Attribute Values, ä¸åŒçš„ç¼–ç /å‘½åæ–¹æ¡ˆDifferent Coding/Naming Schemes, ä¸å¯è¡Œçš„å€¼Infeasible Values, ä¸ä¸€è‡´çš„æ•°æ®InconsistentData, å¼‚å¸¸å€¼Outliers

**Data Quality** : Accuracy ï¼ˆå‡†ç¡®æ€§ï¼‰, Completenessï¼ˆå®Œæ•´æ€§ï¼‰, Consistency ï¼ˆä¸€è‡´æ€§ï¼‰, Interpretabilityï¼ˆå¯è§£é‡Šæ€§ï¼‰, Credibilityï¼ˆå¯ä¿¡æ€§ï¼‰, Timelinessï¼ˆæ—¶æ•ˆæ€§ï¼‰

**æ•°æ®é›†æˆ** : ç»„åˆæ¥è‡ªä¸åŒæ¥æºçš„æ•°æ®ã€‚

**æ•°æ®ç¼©å‡** : ç‰¹å¾é€‰æ‹©ã€æŠ½æ ·

**Privacy**

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/privacy.png?raw=true" width="100%">

**No Free Lunch**

Why bother so many different algorithms?

+ No algorithm is always superior to others.
+ No parameter settingis optimal over all problems.

Look for the best match between problem and algorithm.

+ Experience
+ Trial and Error

Factors to consider:
+ Applicability
+ Computational Complexity
+ Interpretability

Always start with simple ones.

OUTLINES of Data Preprocessing
## Data Cleaning æ•°æ®æ¸…æ´—
å¡«å……ç¼ºå¤±å€¼ã€æ›´æ­£ä¸ä¸€è‡´çš„æ•°æ®ã€è¯†åˆ«å¼‚å¸¸å€¼å’Œå™ªå£°æ•°æ®ã€‚
### ç¼ºå¤±å€¼

æ•°æ®ç¼ºå¤±ç±»å‹åˆ†ä¸ºä¸‰ç§ï¼šå®Œå…¨éšæœºç¼ºå¤±ã€éšæœºç¼ºå¤±ã€ééšæœºç¼ºå¤±ã€‚

å¦‚ä½•å¤„ç†ç¼ºå¤±æ•°æ®ï¼Ÿ
+ å¿½ç•¥ï¼šåˆ é™¤æœ‰ç¼ºå¤±å€¼çš„æ ·æœ¬/å±æ€§ï¼Œæœ€ç®€å•ã€æœ€ç›´æ¥çš„æ–¹æ³•ï¼Œä½ç¼ºå¤±ç‡æ—¶æ•ˆæœå¾ˆå¥½
+ æ‰‹åŠ¨å¡«å†™ç¼ºå¤±å€¼ï¼šé‡æ–°æ”¶é›†æ•°æ®æˆ–é¢†åŸŸçŸ¥è¯†ï¼Œç¹ç/ä¸å¯è¡Œ
+ è‡ªåŠ¨å¡«å†™ç¼ºå¤±å€¼ï¼šå…¨å±€å¸¸æ•°/å¹³å‡å€¼æˆ–ä¸­ä½æ•°/æœ€å¯èƒ½çš„å€¼

**Outliersï¼ˆç¦»ç¾¤ç‚¹ï¼‰**

**Anomalyï¼ˆå¼‚å¸¸ç‚¹ï¼‰ vs. Outlierï¼ˆç¦»ç¾¤ç‚¹ï¼‰**

## Data Transformation æ•°æ®è½¬æ¢
è§„èŒƒåŒ–Normalizationã€ èšåˆAggregationã€ç±»å‹è½¬æ¢ã€‚
## Data Description

## Feature Selection

## Feature Extraction


## Conditional IndependenceÂ Â Â 


**Independent** â‰  **Uncorrelated**

e.g. When \\( X \in [-1, 1] \\), then \\( Y = x^2 \\).

\\( \text{Cov}(X, Y) = 0 \\) indicating that \\( X \\) and \\( Y \\) are **uncorrelated**, even though \\( Y \\) is **completely determined** by \\( X \\).

## ID3 Framework

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/ID3Framework.png?raw=true" width="100%">

+ å¶èŠ‚ç‚¹ä¸ºçº¯èŠ‚ç‚¹ï¼Œstop.
+ å¶èŠ‚ç‚¹ä¸ºç©ºèŠ‚ç‚¹ï¼Œå¦‚ä½•å†³å®šè¯¥èŠ‚ç‚¹çš„åˆ†ç±»ï¼Ÿæ ¹æ®çˆ¶èŠ‚ç‚¹çš„æ¯”ä¾‹
+ å±æ€§ç”¨å®Œäº†ä¹Ÿæ— æ³•åˆ†ç±»ï¼šæ ‘æ— æ³•ç”Ÿé•¿ï¼Œæ ¹æ®å ä¼˜æ¯”ä¾‹å†³å®šç±»åˆ«ã€‚

**å¥¥å¡å§†å‰ƒåˆ€**ï¼šå€¾å‘äºé€‰æ‹©æ›´ç®€å•çš„æ¨¡å‹

**over fitting**ï¼šæ³›åŒ–è¯¯å·®å°ï¼Œæµ‹è¯•è¯¯å·®å¤§ï¼ˆé¢å¤–åˆ’å‡ºValidation Setæ¥åˆ¤å®šæ˜¯å¦è¿‡æ‹Ÿåˆï¼‰

è§£å†³ï¼šæ—©åœï¼ŒLossåŠ å…¥æ­£åˆ™é¡¹ï¼Œåˆ©ç”¨æ–°æ¨¡å‹

å†³ç­–æ ‘è§£å†³è¿‡æ‹Ÿåˆçš„æ–¹æ³•ï¼š**å‰ªæ**

+ é¢„å‰ªæï¼šç”Ÿæˆå†³ç­–æ ‘æ—¶ï¼Œå¯¹æ¯ä¸ªèŠ‚ç‚¹åœ¨åˆ’åˆ†å‰å…ˆè¿›è¡Œä¼°è®¡ï¼Œè‹¥ä¸èƒ½å¸¦æ¥æ³›åŒ–æ€§èƒ½çš„æå‡ï¼Œåˆ™åœæ­¢åˆ’åˆ†ã€‚ï¼ˆä¸»è¦ç”¨åˆ°çš„æ ‡å‡†æ˜¯éªŒè¯é›†çš„ç²¾åº¦ï¼‰
+ åå‰ªæ:ç”Ÿæˆå®Œæ•´çš„å†³ç­–æ ‘ï¼Œè‡ªåº•å‘ä¸Šå‘å¶èŠ‚ç‚¹è¿›è¡Œè€ƒå¯Ÿï¼Œè‹¥è¯¥èŠ‚ç‚¹å¯¹åº”çš„å­æ ‘æ›¿æ¢æˆå¶èŠ‚ç‚¹èƒ½å¸¦æ¥æ³›åŒ–æ€§èƒ½çš„æå‡ï¼Œåˆ™æ›¿æ¢æˆå¶èŠ‚ç‚¹ã€‚

**Entropy Bias**

ä¿¡æ¯å¢ç›Šç‡
\\( \text{Cov}(X, Y) = 0 \\) indicating that \\( X \\) and \\( Y \\) are **uncorrelated**, even though \\( Y \\) is **completely determined** by \\( X \\).

# Optimization

# Convolutional Neural Networks

## Backpropagation åå‘ä¼ æ’­

## FUlly connected layers

å‚æ•°é‡

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/bd_fc_num.png?raw=true" width="100%">

## Convolution arithmetic å·ç§¯

## Pooling arithmetic æ± åŒ–

# Classifier

## Linear Classifier

## SVM æ”¯æŒå‘é‡æœº

$$ y_i(w\cdot x_i+b)-1\ge 0 $$

$$ a_i \ge 0 $$ 

$$ a_i[y_i(w\cdot x_i+b)-1]=0 $$

åªæœ‰æ”¯æŒå‘é‡åœ¨èµ·ä½œç”¨

### Soft Margin

$$
y_{i}(w x_{i}+\partial)-1+\xi_{i}\geq0
$$

$$\Phi(w)=\frac{1}{2}\,w^{t}w+C\sum_{i}\xi_{i}$$

$$\xi_{r}\geq0$$

$${\cal L}_{P} \equiv\frac{1}{2}\Bigl|w\Bigr|^{2}+C\sum_{i=1}^{l}\xi_{i}-\sum_{i=1}^{l}\alpha_{i}[y_{i}(w\cdot x_{i}+b)-1+\xi_{i}]-\sum_{i=1}^{l}\mu_{i}\xi_{i}$$

### éçº¿æ€§SVMs ï¼ˆNon-linear SVMsï¼‰

**Feature Space**ï¼š
å‘é«˜é˜¶ç©ºé—´è¿›è¡Œæ˜ å°„ï¼Œå¯ä»¥æŠŠå¾ˆå¤šä¸èƒ½ç”¨linear SVMè§£å†³çš„é—®é¢˜ä½¿ç”¨linear SVMè§£å†³

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/nonlinearSVMs.png?raw=true" width="100%">

Which kind of $$\varphi(x)$$ can solve this problem?

**Kernel Trick** 

$$K(x_{i}x_{j})=\varphi(x_{i})*\varphi(x_{j})$$

$$\mathcal{\Phi}\colon\,x\longrightarrow\mathcal{\varphi}(x)$$

$$x_{i}*x_{j}\longrightarrow\varphi(x_{i})*\varphi(x_{j})$$

**Solutions of w & b**


é—®é¢˜ï¼šåœ¨SVMå½“ä¸­è¿›è¡Œç©ºé—´æ˜ å°„çš„ä¸»è¦ç›®çš„æ˜¯:
- A é™ä½è®¡ç®—å¤æ‚åº¦ ï¼ˆæé«˜ï¼‰
- B æå–è¾ƒä¸ºé‡è¦çš„ç‰¹å¾
- C å¯¹åŸå§‹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–
- D æé«˜åŸå§‹é—®é¢˜çš„å¯åˆ†æ€§ âˆš

é—®é¢˜ï¼šå¯¹äºSVMï¼Œåœ¨æ˜ å°„åçš„é«˜ç»´ç©ºé—´ç›´æ¥è¿›è¡Œè®¡ç®—çš„ä¸»è¦é—®é¢˜æ˜¯:
- A æ¨¡å‹å¯è§£é‡Šæ€§å·®
- B è®¡ç®—å¤æ‚åº¦é«˜ âˆš
- C å®¹æ˜“å‡ºç°å¥‡å¼‚çŸ©é˜µ
- D å®¹æ˜“å‡ºç°ç¨€ç–çŸ©é˜µ

é—®é¢˜ï¼šæ‰€è°“kernel trickï¼ŒæŒ‡çš„æ˜¯:
- A åˆ©ç”¨åœ¨åŸå§‹ç©ºé—´å®šä¹‰çš„å‡½æ•°æ›¿ä»£é«˜ç»´ç©ºé—´çš„å‘é‡å†…ç§¯æ“ä½œ âˆš
- B åˆ©ç”¨åœ¨é«˜ç»´ç©ºé—´å®šä¹‰çš„å‡½æ•°æ›¿ä»£åŸå§‹ç©ºé—´çš„å‘é‡å†…ç§¯æ“ä½œ
- C æ ¸å‡½æ•°çš„å¯¼æ•°å…·æœ‰ç®€å•çš„è§£æè§£ï¼Œç®€åŒ–äº†è¿ç®—
- D æ ¸å‡½æ•°å…·æœ‰å›ºå®šçš„ä¸Šä¸‹ç•Œï¼Œå¯ä»¥è¾“å‡º$$(-1,+1)$$åŒºé—´ä¸­çš„è¿ç»­å€¼



# é›†æˆå­¦ä¹  

## bagging

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/bootstrap.png?raw=true" width="100%">

## æœ‰æ”¾å›é‡‡æ ·
æœ‰å¤šå°‘æ ·æœ¬æ²¡æœ‰è¢«å‹‡æ•¢ä½†æ˜¯è¢«ä»¥ä¸ºæ˜¯å¯ä»¥testçš„ OOB
å¥½å¤„ï¼šå¯ä»¥å¸®æˆ‘ä»¬æ„å»ºå…·æœ‰åˆ†æ•£æ€§çš„åŸºç¡€åˆ†ç±»å™¨
å……åˆ†åˆ©ç”¨æ‰€æœ‰æ ·æœ¬

## ä¿è¯åŸºç¡€åˆ†ç±»å™¨å¤šæ ·æ€§çš„æ–¹æ³•
+ ç®—æ³•å¤šæ ·æ€§
+ è®­ç»ƒé›†ï¼ˆéšæœºåˆæ”¾å›é‡‡æ ·ï¼‰
+ é€‰æ‹©ä¸åŒçš„å±æ€§ï¼Œå†³ç­–æ ‘ä¸­ç”¨$$\sqrt{K}$$ä¸ªå±æ€§æ„é€ 500-5000æ£µæ ‘
+ è¶…å‚æ•°


## Stack

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/stack.png?raw=true" width="100%">

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/stacking.png?raw=true" width="100%">

## Boosting
 **Adaboost**

