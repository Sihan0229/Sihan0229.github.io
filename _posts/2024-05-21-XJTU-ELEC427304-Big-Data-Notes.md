---
layout: post  
title: "XJTU-ELEC427304 Big Data Notes"  
date: 2024-06-04 19:10 +0800  
last_modified_at: 2024-06-09 19:18 +0800  
tags: [Course Note]  
math: true  r
toc: true 
excerpt: "Course notes of XJTU-ELEC427304 (TBC)."
---
<style>
        /* å…¨å±€è‹±æ–‡å­—ä½“è®¾ç½®ä¸º Times */
        :lang(en) {
            font-family: Times, serif !important;
        }
        
        /* å…¨å±€ä¸­æ–‡å­—ä½“è®¾ç½®ä¸ºé»˜è®¤ */
        :lang(zh) {
            font-family: sans-serif !important;
        }

        /* å…·ä½“æ ·å¼ */
        h1 { font: 26pt Times !important; }
        h2 { font: 20pt Times !important; }
        h3 { font: 16pt Times !important; }
        p { font: 12pt Times !important; }
</style>

# Introduction

**PAC - probably Approximately Correct learning model**

$$
P(|f(x)-y|\le \epsilon)\ge 1-\delta
$$

**Data Types**

+ Continuous, Binary
+ Discrete, String
+ Symbolic

**Big Data** is high-volume, high-velocity, high-variety, demanding cost-effective, innovative forms of imformation processing, whose size is beyongd the ability of typical database software tools to capture, store, manage, and analyze.

**Data Mining** is the process of discovering patterns in large data set, including intersection of ML, statistic and database systems.

ä¹ é¢˜1ï¼šå¤§æ•°æ®çš„ç‰¹ç‚¹åŒ…æ‹¬ç±»å‹å¤šã€å¯¹å¤„ç†å®æ—¶æ€§è¦æ±‚é«˜ã€å®¹é‡å¤§

ä¹ é¢˜2ï¼šç†æƒ³çš„æ•°æ®æŒ–æ˜ç®—æ³•å¾—åˆ°çš„ç»“æœåº”è¯¥æ˜¯ï¼šUseful, Hidden, Interesting

**Source & Materials**
[KDnuggets](https://www.kdnuggets.com/), [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets.php)

**Framework of ML**

+ Step 1: function with unknown

$$
y=f_\theta(x)
$$

+ Step 2: define loss from training data

$$
L(\theta)
$$

+ Step 3: optimization

$$
\theta^* = \arg \min_{\theta} \mathcal{L}
$$

**DM Techniques - Classification**
Decision Trees, K-Nearest Neighbours, Neural Networks, Support Vector Machines

# Evaluation method of model

## Data Segmentation

**hold-out ç•™å‡ºæ³•** ä¿æŒæ•°æ®åˆ†å¸ƒä¸€è‡´æ€§ï¼Œå¤šæ¬¡é‡å¤éšæœºåˆ’åˆ†ï¼Œæµ‹è¯•é›†ä¸èƒ½å¤ªå¤§ã€ä¸èƒ½å¤ªå°

**cross-validation äº¤å‰éªŒè¯æ³•** kæŠ˜äº¤å‰éªŒè¯

**boostrapping è‡ªåŠ©æ³•** æœ‰æ”¾å›/å¯é‡å¤é‡‡æ ·ï¼Œæ•°æ®åˆ†å¸ƒæœ‰æ‰€æ”¹å˜ï¼Œè®­ç»ƒé›†ä¸åŸæ ·æœ¬é›†åŒè§„æ¨¡
ï¼ˆåŒ…å¤–ä¼°è®¡ out-of-bag estimationï¼‰

## Model performance

**Error rate é”™è¯¯ç‡**

$$
E(ğ‘“;ğ·)=\frac{1}{m}\Sigma_{i=1}^{m}I(f(ğ’™_i)â‰ ğ‘¦)
$$

**Accuracy ç²¾åº¦**

$$
Acc(ğ‘“;ğ·)=\frac{1}{m}\Sigma_{i=1}^{m}I(f(ğ’™_i)=ğ‘¦)=1-E(ğ‘“;ğ·)
$$

**Precision æŸ¥å‡†ç‡**

$$
P=\frac{TP}{TP+FP}
$$

**Recall æŸ¥å…¨ç‡**

$$
R=\frac{TP}{TP+FN}
$$

**F1**

$$
\frac{1}{F_1}=\frac{1}{2}(\frac{1}{R}+\frac{1}{P})
$$

**FÎ²**

$$
\frac{1}{F_\beta}=\frac{1}{1+\beta^2}(\frac{\beta^2}{R}+\frac{1}{P})
$$

**Confusion Matrix æ··æ·†çŸ©é˜µ**

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/ConfusionMatrix.png?raw=true" width="100%">

**P-Ræ›²çº¿**

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/pr.png?raw=true" width="60%">

**BEP å¹³è¡¡ç‚¹ Break-Even Point** æŸ¥å‡†ç‡ = æŸ¥å…¨ç‡çš„å–å€¼

**ROC å—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿**

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/roc.png?raw=true" width="100%">

**AUC**ï¼šROCæ›²çº¿ä¸‹é¢ç§¯

How to Construct an ROC curve

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/rocCurve.png?raw=true" width="100%">

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/rocCurve2.png?raw=true" width="100%">

**Cost Matrix**
Cost-sensitive error rate and cost curve

**DM Techniques - Classification**:Â K-Means, Sequential Leader, Affinity Propagation

**DM Techniques â€“ Association Rule**

**DM Techniques â€“ Regression**

**Overfitting**Â 

# Data Preprocessing

## Conditional IndependenceÂ Â Â 

**Independent** â‰  **Uncorrelated**

e.g. When \\( X \in [-1, 1] \\), then \\( Y = x^2 \\).

\\( \text{Cov}(X, Y) = 0 \\) indicating that \\( X \\) and \\( Y \\) are **uncorrelated**, even though \\( Y \\) is **completely determined** by \\( X \\).

## ID3 Framework

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/ID3Framework.png?raw=true" width="100%">

+ å¶èŠ‚ç‚¹ä¸ºçº¯èŠ‚ç‚¹ï¼Œstop.
+ å¶èŠ‚ç‚¹ä¸ºç©ºèŠ‚ç‚¹ï¼Œå¦‚ä½•å†³å®šè¯¥èŠ‚ç‚¹çš„åˆ†ç±»ï¼Ÿæ ¹æ®çˆ¶èŠ‚ç‚¹çš„æ¯”ä¾‹
+ å±æ€§ç”¨å®Œäº†ä¹Ÿæ— æ³•åˆ†ç±»ï¼šæ ‘æ— æ³•ç”Ÿé•¿ï¼Œæ ¹æ®å ä¼˜æ¯”ä¾‹å†³å®šç±»åˆ«ã€‚

**å¥¥å¡å§†å‰ƒåˆ€**ï¼šå€¾å‘äºé€‰æ‹©æ›´ç®€å•çš„æ¨¡å‹

**over fitting**ï¼šæ³›åŒ–è¯¯å·®å°ï¼Œæµ‹è¯•è¯¯å·®å¤§ï¼ˆé¢å¤–åˆ’å‡ºValidation Setæ¥åˆ¤å®šæ˜¯å¦è¿‡æ‹Ÿåˆï¼‰

è§£å†³ï¼šæ—©åœï¼ŒLossåŠ å…¥æ­£åˆ™é¡¹ï¼Œåˆ©ç”¨æ–°æ¨¡å‹

å†³ç­–æ ‘è§£å†³è¿‡æ‹Ÿåˆçš„æ–¹æ³•ï¼š**å‰ªæ**

+ é¢„å‰ªæï¼šç”Ÿæˆå†³ç­–æ ‘æ—¶ï¼Œå¯¹æ¯ä¸ªèŠ‚ç‚¹åœ¨åˆ’åˆ†å‰å…ˆè¿›è¡Œä¼°è®¡ï¼Œè‹¥ä¸èƒ½å¸¦æ¥æ³›åŒ–æ€§èƒ½çš„æå‡ï¼Œåˆ™åœæ­¢åˆ’åˆ†ã€‚ï¼ˆä¸»è¦ç”¨åˆ°çš„æ ‡å‡†æ˜¯éªŒè¯é›†çš„ç²¾åº¦ï¼‰
+ åå‰ªæ:ç”Ÿæˆå®Œæ•´çš„å†³ç­–æ ‘ï¼Œè‡ªåº•å‘ä¸Šå‘å¶èŠ‚ç‚¹è¿›è¡Œè€ƒå¯Ÿï¼Œè‹¥è¯¥èŠ‚ç‚¹å¯¹åº”çš„å­æ ‘æ›¿æ¢æˆå¶èŠ‚ç‚¹èƒ½å¸¦æ¥æ³›åŒ–æ€§èƒ½çš„æå‡ï¼Œåˆ™æ›¿æ¢æˆå¶èŠ‚ç‚¹ã€‚

**Entropy Bias**

ä¿¡æ¯å¢ç›Šç‡
\\( \text{Cov}(X, Y) = 0 \\) indicating that \\( X \\) and \\( Y \\) are **uncorrelated**, even though \\( Y \\) is **completely determined** by \\( X \\).

# Optimization

# Convolutional Neural Networks

## Backpropagation åå‘ä¼ æ’­

## FUlly connected layers

å‚æ•°é‡

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/bd_fc_num.png?raw=true" width="100%">

## Convolution arithmetic å·ç§¯

## Pooling arithmetic æ± åŒ–

# Classifier

## Linear Classifier

## SVM æ”¯æŒå‘é‡æœº

$$ y_i(w\cdot x_i+b)-1\ge 0 $$

$$ a_i \ge 0 $$ 

$$ a_i[y_i(w\cdot x_i+b)-1]=0 $$

åªæœ‰æ”¯æŒå‘é‡åœ¨èµ·ä½œç”¨

### Soft Margin

$$
y_{i}(w x_{i}+\partial)-1+\xi_{i}\geq0
$$

$$\Phi(w)=\frac{1}{2}\,w^{t}w+C\sum_{i}\xi_{i}$$

$$\xi_{r}\geq0$$

$${\cal L}_{P} \equiv\frac{1}{2}\Bigl|w\Bigr|^{2}+C\sum_{i=1}^{l}\xi_{i}-\sum_{i=1}^{l}\alpha_{i}[y_{i}(w\cdot x_{i}+b)-1+\xi_{i}]-\sum_{i=1}^{l}\mu_{i}\xi_{i}$$

### éçº¿æ€§SVMs ï¼ˆNon-linear SVMsï¼‰

**Feature Space**ï¼š
å‘é«˜é˜¶ç©ºé—´è¿›è¡Œæ˜ å°„ï¼Œå¯ä»¥æŠŠå¾ˆå¤šä¸èƒ½ç”¨linear SVMè§£å†³çš„é—®é¢˜ä½¿ç”¨linear SVMè§£å†³

<img src="https://github.com/Sihan0229/Sihan0229.github.io/blob/master/assets/nonlinearSVMs.png?raw=true" width="100%">

Which kind of $$\varphi(x)$$ can solve this problem?

**Kernel Trick** 

$$K(x_{i}x_{j})=\varphi(x_{i})*\varphi(x_{j})$$

$$\mathcal{\Phi}\colon\,x\longrightarrow\mathcal{\varphi}(x)$$

$$x_{i}*x_{j}\longrightarrow\varphi(x_{i})*\varphi(x_{j})$$

**Solutions of w & b**


é—®é¢˜ï¼šåœ¨SVMå½“ä¸­è¿›è¡Œç©ºé—´æ˜ å°„çš„ä¸»è¦ç›®çš„æ˜¯:
- A é™ä½è®¡ç®—å¤æ‚åº¦ ï¼ˆæé«˜ï¼‰
- B æå–è¾ƒä¸ºé‡è¦çš„ç‰¹å¾
- C å¯¹åŸå§‹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–
- D æé«˜åŸå§‹é—®é¢˜çš„å¯åˆ†æ€§ âˆš

é—®é¢˜ï¼šå¯¹äºSVMï¼Œåœ¨æ˜ å°„åçš„é«˜ç»´ç©ºé—´ç›´æ¥è¿›è¡Œè®¡ç®—çš„ä¸»è¦é—®é¢˜æ˜¯:
- A æ¨¡å‹å¯è§£é‡Šæ€§å·®
- B è®¡ç®—å¤æ‚åº¦é«˜ âˆš
- C å®¹æ˜“å‡ºç°å¥‡å¼‚çŸ©é˜µ
- D å®¹æ˜“å‡ºç°ç¨€ç–çŸ©é˜µ

é—®é¢˜ï¼šæ‰€è°“kernel trickï¼ŒæŒ‡çš„æ˜¯:
- A åˆ©ç”¨åœ¨åŸå§‹ç©ºé—´å®šä¹‰çš„å‡½æ•°æ›¿ä»£é«˜ç»´ç©ºé—´çš„å‘é‡å†…ç§¯æ“ä½œ âˆš
- B åˆ©ç”¨åœ¨é«˜ç»´ç©ºé—´å®šä¹‰çš„å‡½æ•°æ›¿ä»£åŸå§‹ç©ºé—´çš„å‘é‡å†…ç§¯æ“ä½œ
- C æ ¸å‡½æ•°çš„å¯¼æ•°å…·æœ‰ç®€å•çš„è§£æè§£ï¼Œç®€åŒ–äº†è¿ç®—
- D æ ¸å‡½æ•°å…·æœ‰å›ºå®šçš„ä¸Šä¸‹ç•Œï¼Œå¯ä»¥è¾“å‡º(-1ï¼Œ+1)åŒºé—´ä¸­çš„è¿ç»­å€¼
