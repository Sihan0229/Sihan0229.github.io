---
layout: post  
title: "Generating Radiology Reports via Memory-driven Transformer解读"  
date: 2024-07-19 00:10 +0800  
last_modified_at: 2024-07-19 14:00 +0800  
tags: [Computer Vision]  
math: true  r
toc: true  
excerpt: "Generating Radiology Reports via Memory-driven Transformer解读（与改进）"
---

# 原文源码
[原文：Generating Radiology Reports via Memory-driven Transformer](https://arxiv.org/pdf/2010.16056)

[源码：R2Gen](https://github.com/cuhksz-nlp/R2Gen)

# 研究动机

内容是模式化的，相似的陈述与上下文关系通常会在不同的报告中重复出现。可以作为生成报告的参考。

# 主要贡献
+ 关系记忆网络（Relational Memory）

+ 记忆驱动的条件层归一化（Memory-driven Conditional Layer Normalization）

+ 在解码端使用辅助的记忆模块来记录生成过程中的关键信息，并引入条件层归一化来更细粒度地融合上述记忆信息。充分利用训练数据中的关联文本和知识指导文本生成过程。

# 代码解读
## VisualExtractor部分

```python
class VisualExtractor(nn.Module):
    def __init__(self, args):
        super(VisualExtractor, self).__init__()
        self.visual_extractor = args.visual_extractor # 使用的视觉提取器模型的名称。
        self.pretrained = args.visual_extractor_pretrained # 是否使用预训练的视觉提取器模型。
        # 使用 getattr 函数根据模型名称从 torchvision.models 模块中加载对应的预训练模型，
        # 根据 visual_extractor_pretrained 参数决定是否使用预训练模型
        model = getattr(models, self.visual_extractor)(pretrained=self.pretrained)
        # 获取模型的所有子模块，并且去除了最后两个子模块（通常是全局池化层和分类器层）
        modules = list(model.children())[:-2]
        # 构建一个顺序模型
        self.model = nn.Sequential(*modules)
        # 创建一个平均池化层，用于计算图像的平均特征。
        self.avg_fnt = torch.nn.AvgPool2d(kernel_size=7, stride=1, padding=0)

    def forward(self, images):
        patch_feats = self.model(images) # 得到图像的特征表示
        # 池化+去掉维度+改变维度
        avg_feats = self.avg_fnt(patch_feats).squeeze().reshape(-1, patch_feats.size(1))
        batch_size, feat_size, _, _ = patch_feats.shape
        # 将提取的特征进行形状变换
        patch_feats = patch_feats.reshape(batch_size, feat_size, -1).permute(0, 2, 1) 
        return patch_feats, avg_feats
```
# 步骤概要

+ **筛选带有癌变区域的图像：使用区域分类器SEResNeXt**，因为能够同时增加网络深度和网络宽度，这允许使用更多参数来实现更好的性能。

+ **提取视觉特征：预训练的ResNet101**，建模为序列，不需要实时性

+ **提取特征信息：Transformer**，因为其自注意力机制能够同时考虑到输入序列中的所有位置，捕捉全局信息。

+ **信息增强模块IEM：LLMs**提取报告关键信息

+ **记忆提取MRM**：“子宫内膜癌侵及宫体深肌层” ， “内膜异常增厚” 等描述较为常见。将词句向量化。 对于那些存在相关性的词语， 我们用一个矩阵来表示和存储它们向量化后的结果。 在生成过程中， 该矩阵将通过合并之前时间片得到的输出来逐步更新。 选用添加了残差连接的多层感知机MLP，我们还模仿LSTM的**门控模式**给MRM添加了门控机制。

# 评估指标

- **BLEU**（Bilingual Evaluation understudy）

    根据**精确率**，分析候选译文中有多少n元词组出现在参考译文中。
    当参考译文比候选译文长时，这种匹配机制可能并不准确，为此我们引入一个惩罚因子。

    生成文本中有多少是精准的、有必要出现的。

- **ROUGE** （recall-oriented understanding for gisting evaluation）

    基于**召回率**，参考译文中有多少词组在候选译文中出现了，衡量**完整性和涵盖程度**无法评价流畅度。

- **METEOR**

    融合了准确率、召回率，利用二者的调和平均值。**候选译文的同义词**。

- **CIDEr**

    BLEU + 向量空间模型（TF-IDF 余弦夹角）

    可以给不同的词不同的权重，强调重要词汇的出现

# 参考博客

[1] [【论文笔记】Generating Radiology Reports via Memory-driven Transformer](https://blog.csdn.net/m0_47779101/article/details/124493310)

[2] [Generating Radiology Reports via Memory-driven Transformer （EMNLP-2020）](https://blog.csdn.net/weixin_44384749/article/details/118226074)
